{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mnist\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first time you run this might be a bit slow, since the\n",
    "# mnist package has to download and cache the data.\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape) # (60000, 28, 28)\n",
    "print(train_labels.shape) # (60000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "\n",
    "Before we begin, we’ll normalize the image pixel values from [0, 255] to [-0.5, 0.5] to make our network easier to train (using smaller, centered values usually leads to better results). We’ll also reshape each image from (28, 28) to (28, 28, 1) because Keras requires the third dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images.\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the images.\n",
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "test_images = np.expand_dims(test_images, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape) # (60000, 28, 28, 1)\n",
    "print(test_images.shape)  # (10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "Every Keras model is either built using the Sequential class, which represents a linear stack of layers, or the functional Model class, which is more customizeable. We’ll be using the simpler Sequential model, since our CNN will be a linear stack of layers.\n",
    "<br>We start by instantiating a Sequential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sequential constructor takes an array of Keras Layers. We’ll use 3 types of layers for our CNN: Convolutional, Max Pooling, and Softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filters = 8\n",
    "filter_size = 3\n",
    "pool_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zshnh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zshnh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zshnh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zshnh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
    "  MaxPooling2D(pool_size=pool_size),\n",
    "  Flatten(),\n",
    "  Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> 1) num_filters, filter_size, and pool_size are self-explanatory variables that set the hyperparameters for our CNN.\n",
    "<br> 2) The first layer in any Sequential model must specify the input_shape, so we do so on Conv2D. Once this input shape is specified, Keras will automatically infer the shapes of inputs for later layers.\n",
    "<br> 3) The output Softmax layer has 10 nodes, one for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the Model\n",
    "\n",
    "Before we can begin training, we need to configure the training process. We decide 3 key factors during the compilation step:\n",
    "<br> 1) The __optimizer__. We’ll stick with a pretty good default: the Adam gradient-based optimizer. Keras has many other optimizers you can look into as well.\n",
    "<br> 2) The __loss function__. Since we’re using a Softmax output layer, we’ll use the Cross-Entropy loss. Keras distinguishes between __binary_crossentropy__ (2 classes) and __categorical_crossentropy__ (>2 classes), so we’ll use the latter. See all Keras losses.\n",
    "<br> 3) A list of metrics. Since this is a classification problem, we’ll just have Keras report on the __accuracy__ metric.\n",
    "<br>\n",
    "<br>Here’s what that compilation looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zshnh\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zshnh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "  'adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Training a model in Keras literally consists only of calling fit() and specifying some parameters. There are a lot of possible parameters, but we’ll only supply these:\n",
    "<br> 1) The __training data__ (images and labels), commonly known as X and Y, respectively.\n",
    "<br> 2) The __number of epochs__ (iterations over the entire dataset) to train for.\n",
    "<br> 3) The __validation data__ (or test data), which is used during training to periodically measure the network’s performance against data it hasn’t seen before.\n",
    "<br>\n",
    "<br>\n",
    "There’s one thing we have to be careful about: Keras expects the training targets to be _10-dimensional vectors_ , since there are 10 nodes in our Softmax output layer. Right now, our __train_labels__ and __test_labels__ arrays contain single integers representing the class for each image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[0]) # 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conveniently, Keras has a utility method that fixes this exact issue: to_categorical. It turns our array of class integers into an array of one-hot vectors instead. For example, 2 would become [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] (it’s zero-indexed).\n",
    "<br> Here’s what that looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zshnh\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\zshnh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zshnh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zshnh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\zshnh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zshnh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zshnh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zshnh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zshnh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.3484 - acc: 0.8975 - val_loss: 0.2014 - val_acc: 0.9420\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.1750 - acc: 0.9490 - val_loss: 0.1317 - val_acc: 0.9631\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.1254 - acc: 0.9639 - val_loss: 0.1112 - val_acc: 0.9673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d6b903ef60>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=3,\n",
    "  validation_data=(test_images, to_categorical(test_labels)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the first 5 test images\n",
    "predictions = model.predict(test_images[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[:5]) # [7, 2, 1, 0, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk.\n",
    "model.save_weights('cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "There’s much more we can do to experiment with and improve our network - in this official Keras MNIST CNN example, they achieve 99.25% test accuracy after 12 epochs. Some examples of modifications you could make to our CNN include:\n",
    "Network Depth\n",
    "<br> What happens if we add or remove Convolutional layers? How does that affect training and/or the model’s final performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
    "  Conv2D(num_filters, filter_size),\n",
    "  MaxPooling2D(pool_size=pool_size),\n",
    "  Flatten(),\n",
    "  Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "What if we tried adding Dropout layers, which are commonly used to prevent overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zshnh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zshnh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "model = Sequential([\n",
    "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
    "  MaxPooling2D(pool_size=pool_size),\n",
    "  Dropout(0.5),\n",
    "  Flatten(),\n",
    "  Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully-connected Layers\n",
    "What if we add fully-connected layers between the Convolutional outputs and the final Softmax layer? This is something commonly done in CNNs used for Computer Vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
    "  MaxPooling2D(pool_size=pool_size),\n",
    "  Flatten(),\n",
    "  Dense(64, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Parameters\n",
    "\n",
    "What if we play with the Conv2D parameters? For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These can be changed, too!\n",
    "num_filters = 8\n",
    "filter_size = 3\n",
    "\n",
    "model = Sequential([\n",
    "  # See https://keras.io/layers/convolutional/#conv2d for more info.\n",
    "  Conv2D(\n",
    "    num_filters,\n",
    "    filter_size,\n",
    "    input_shape=(28, 28, 1),\n",
    "    strides=2,\n",
    "    padding='same',\n",
    "    activation='relu',\n",
    "  ),\n",
    "  MaxPooling2D(pool_size=pool_size),\n",
    "  Flatten(),\n",
    "  Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model.\n",
    "model.compile(\n",
    "  'adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1360 - acc: 0.9594 - val_loss: 0.1278 - val_acc: 0.9610\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.1204 - acc: 0.9637 - val_loss: 0.1133 - val_acc: 0.9657\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1102 - acc: 0.9668 - val_loss: 0.1052 - val_acc: 0.9690\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1041 - acc: 0.9676 - val_loss: 0.1029 - val_acc: 0.9677\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0989 - acc: 0.9694 - val_loss: 0.1024 - val_acc: 0.9686\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0954 - acc: 0.9711 - val_loss: 0.0981 - val_acc: 0.9698\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0927 - acc: 0.9718 - val_loss: 0.0938 - val_acc: 0.9701\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0895 - acc: 0.9727 - val_loss: 0.0997 - val_acc: 0.9669\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0876 - acc: 0.9732 - val_loss: 0.0925 - val_acc: 0.9724\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0865 - acc: 0.9731 - val_loss: 0.0941 - val_acc: 0.9699\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0843 - acc: 0.9734 - val_loss: 0.0918 - val_acc: 0.9706\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.0831 - acc: 0.9745 - val_loss: 0.0920 - val_acc: 0.9700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d6bc376be0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=12,\n",
    "  validation_data=(test_images, to_categorical(test_labels)),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
